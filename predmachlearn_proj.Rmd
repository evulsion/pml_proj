---
title: "Practical Machine Learning Course Project"
output: html_document
---

First, we input the training data and omit the following columns from it:

* non-numeric columns
* columns containing NA values
* subject id and timestamps

Second, we normalize the data and add back the classe column to it.

Third, we split training data into training and testing sets to perform cross-validation.

Fourth, we train a random forest model on the training data.

Finally, we predict testing set outcomes based on the model and display confusion matrix and statistics. As the out of sample model accuracy is 0.9953 with a 95% confidence interval of (0.9935, 0.9967) we consider the model to be satisfactory to our purposes.

```{r}
# input training data
d0 <- read.csv("pml-training.csv")

library(caret)
library(randomForest)

set.seed(424423)

# select only numeric columns and the "classe" column
nums <- sapply(d0, is.numeric)
d2 <- d0[,nums]

# remove all columns containing at least one NA
d3 <- d2[,colSums(is.na(d2)) == 0]

# remove subject id and timestamps ie three first columns
d4 <- d3[,-c(1:3)]

# normalize the data
pP <- preProcess(d4)
d5 <- predict(pP, d4)

# add the "classe" column
d <- cbind(d5, classe = d0$classe)

# split training data into training and testing sets
inTrain <- createDataPartition(y=d$classe, p=0.6, list=F)
training <- d[inTrain,]
testing <- d[-inTrain,]

# train a random forest model on the training data
m <- randomForest(classe ~ ., data=training, ntree=1000, importance=T)

# predict testing set outcomes based on the model and display confusion matrix and statistics
p <- predict(m, testing)
confusionMatrix(p, testing$classe)
```

